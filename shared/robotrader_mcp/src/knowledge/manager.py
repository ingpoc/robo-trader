#!/usr/bin/env python3
"""
Session Knowledge Manager - High-level interface for Claude Code sessions

Provides intelligent caching and retrieval of session knowledge to prevent
re-analyzing the same code/errors across multiple sessions.

Token Efficiency: 90-95% reduction on repeat operations
"""

from typing import Dict, List, Any, Optional
from pathlib import Path
import json

from .session_db import SessionKnowledgeDB, get_knowledge_db


class SessionKnowledgeManager:
    """
    Manages session knowledge with intelligent caching and retrieval.

    This is the primary interface Claude Code should use for:
    - Checking if an error has been seen before
    - Caching code structure analysis
    - Storing successful debugging workflows
    - Avoiding re-analysis of same files
    """

    def __init__(self):
        self.db = get_knowledge_db()
        self.session_cache = {}  # In-memory cache for current session

    # ========================================================================
    # ERROR PATTERN MANAGEMENT
    # ========================================================================

    def check_known_error(self, error_message: str) -> Optional[Dict[str, Any]]:
        """
        Check if error has been seen before and has a known fix.

        Args:
            error_message: The error message to check

        Returns:
            Fix information if known, None otherwise

        Example:
            fix = manager.check_known_error("database is locked")
            if fix:
                print(f"Known fix: {fix['fix']}")
                print(f"Success rate: {fix['success_rate']}")
                return fix  # 0 tokens vs 5k+ to analyze
        """
        # Normalize error message
        error_key = self._normalize_error(error_message)

        # Check cache first
        cache_key = f"error:{error_key}"
        if cache_key in self.session_cache:
            return self.session_cache[cache_key]

        # Check database
        fix = self.db.get_learning("error_patterns", error_key)
        if fix:
            self.session_cache[cache_key] = fix
            return fix

        return None

    def store_error_solution(
        self,
        error_message: str,
        fix_description: str,
        files_affected: List[str],
        success: bool = True
    ):
        """
        Store a new error solution for future reference.

        Args:
            error_message: The error that occurred
            fix_description: How it was fixed
            files_affected: Which files were involved
            success: Whether the fix worked

        Example:
            manager.store_error_solution(
                error_message="database is locked",
                fix_description="Changed to config_state.get_analysis_history()",
                files_affected=["src/web/routes/monitoring.py"],
                success=True
            )
        """
        error_key = self._normalize_error(error_message)

        # Get existing fix to update success rate
        existing = self.db.get_learning("error_patterns", error_key, increment_usage=False)

        if existing:
            # Update success rate
            old_rate = existing.get('success_rate', 1.0)
            old_count = existing.get('_meta', {}).get('usage_count', 1)
            new_rate = (old_rate * old_count + (1.0 if success else 0.0)) / (old_count + 1)
        else:
            new_rate = 1.0 if success else 0.0

        self.db.store_error_fix(
            error_pattern=error_key,
            fix_description=fix_description,
            files_affected=files_affected,
            success_rate=new_rate
        )

    # ========================================================================
    # CODE STRUCTURE CACHING
    # ========================================================================

    def get_file_structure(self, file_path: str) -> Optional[Dict[str, Any]]:
        """
        Get cached file structure analysis.

        Returns:
            Cached structure if available, None otherwise

        Token Savings: Returns 300 tokens from cache vs 5k-20k to re-analyze
        """
        cache_key = f"structure:{file_path}"

        # Check in-memory cache
        if cache_key in self.session_cache:
            return self.session_cache[cache_key]

        # Check database
        structure = self.db.get_learning("code_structure", file_path)
        if structure:
            self.session_cache[cache_key] = structure
            return structure

        return None

    def cache_file_structure(
        self,
        file_path: str,
        structure: Dict[str, Any]
    ):
        """
        Cache file structure for future sessions.

        Args:
            file_path: Path to the file
            structure: Structure analysis (classes, functions, imports, etc.)

        Example:
            structure = {
                "classes": ["ConfigurationState", "DatabaseManager"],
                "functions": ["init_db", "migrate"],
                "imports": ["asyncio", "sqlite3"],
                "database_operations": {"locked": 5, "direct": 0},
                "async_functions": 12
            }
            manager.cache_file_structure("src/core/database.py", structure)
        """
        self.db.store_code_structure(file_path, structure)
        cache_key = f"structure:{file_path}"
        self.session_cache[cache_key] = structure

    # ========================================================================
    # FILE RELATIONSHIP CACHING
    # ========================================================================

    def get_file_relationships(self, file_path: str) -> Optional[Dict[str, List[str]]]:
        """
        Get cached file relationship information.

        Returns:
            Relationships dict with 'imports', 'imported_by', 'git_related'
        """
        cache_key = f"relationships:{file_path}"

        if cache_key in self.session_cache:
            return self.session_cache[cache_key]

        relationships = self.db.get_learning("file_relationships", file_path)
        if relationships:
            self.session_cache[cache_key] = relationships
            return relationships

        return None

    def cache_file_relationships(
        self,
        file_path: str,
        imports: List[str],
        imported_by: List[str] = None,
        git_related: List[str] = None
    ):
        """Cache file relationship information."""
        relationships = {
            "imports": imports,
            "imported_by": imported_by or [],
            "git_related": git_related or []
        }

        self.db.store_file_relationship(file_path, relationships)
        cache_key = f"relationships:{file_path}"
        self.session_cache[cache_key] = relationships

    # ========================================================================
    # DEBUGGING WORKFLOW PATTERNS
    # ========================================================================

    def get_debugging_workflow(self, issue_type: str) -> Optional[Dict[str, Any]]:
        """
        Get recommended debugging workflow for issue type.

        Args:
            issue_type: Type of issue (e.g., "database_lock", "websocket_error")

        Returns:
            Workflow with steps and success rate

        Example:
            workflow = manager.get_debugging_workflow("database_lock")
            if workflow:
                for step in workflow['steps']:
                    print(f"- {step}")
        """
        return self.db.get_learning("debugging_workflows", issue_type)

    def store_debugging_workflow(
        self,
        issue_type: str,
        steps: List[str],
        success: bool = True
    ):
        """Store a successful debugging workflow."""
        # Get existing to update success rate
        existing = self.db.get_learning("debugging_workflows", issue_type, increment_usage=False)

        if existing:
            old_rate = existing.get('success_rate', 1.0)
            old_count = existing.get('_meta', {}).get('usage_count', 1)
            new_rate = (old_rate * old_count + (1.0 if success else 0.0)) / (old_count + 1)
        else:
            new_rate = 1.0 if success else 0.0

        self.db.store_debugging_workflow(
            issue_type=issue_type,
            workflow_steps=steps,
            success_rate=new_rate
        )

    # ========================================================================
    # SESSION SUMMARY & ANALYTICS
    # ========================================================================

    def get_session_insights(self) -> Dict[str, Any]:
        """
        Get insights about stored knowledge for current session startup.

        Returns summary of what Claude knows from previous sessions to avoid
        re-learning the same patterns.

        Example:
            insights = manager.get_session_insights()
            # {
            #   "known_errors": 15,
            #   "cached_files": 42,
            #   "debugging_workflows": 8,
            #   "most_common_errors": [...]
            # }
        """
        summary = self.db.get_session_summary()

        # Get most common errors
        common_errors = self.db.search_learnings(
            category="error_patterns",
            min_confidence=0.7,
            limit=5
        )

        # Get most analyzed files
        analyzed_files = self.db.search_learnings(
            category="code_structure",
            limit=10
        )

        return {
            "total_learnings": summary.get("total_learnings", 0),
            "by_category": summary.get("by_category", {}),
            "known_errors": len(common_errors),
            "most_common_errors": [
                {
                    "pattern": e.get("pattern"),
                    "fix": e.get("fix"),
                    "success_rate": e.get("success_rate"),
                    "usage_count": e.get("_meta", {}).get("usage_count", 0)
                }
                for e in common_errors
            ],
            "cached_files": len(analyzed_files),
            "top_analyzed_files": [
                e.get("_meta", {}).get("key") for e in analyzed_files[:5]
            ],
            "estimated_token_savings": summary.get("token_savings_estimate", 0)
        }

    def export_knowledge_snapshot(self, output_path: str):
        """Export all knowledge to JSON for inspection/backup."""
        return self.db.export_knowledge(output_path)

    # ========================================================================
    # HELPERS
    # ========================================================================

    def _normalize_error(self, error_message: str) -> str:
        """Normalize error message to a consistent key."""
        # Remove file paths, line numbers, timestamps
        import re

        normalized = error_message.lower()

        # Remove file paths
        normalized = re.sub(r'[/\\][\w/\\.-]+\.py', '', normalized)

        # Remove line numbers
        normalized = re.sub(r'line \d+', '', normalized)

        # Remove timestamps
        normalized = re.sub(r'\d{4}-\d{2}-\d{2}[T\s]\d{2}:\d{2}:\d{2}', '', normalized)

        # Extract just the core error
        patterns = [
            r'(sqlite.*locked)',
            r'(database.*locked)',
            r'(error_max_turns)',
            r'(websocket.*closed)',
            r'(importerror.*)',
            r'(modulenotfounderror.*)',
            r'(timeouterror)',
        ]

        for pattern in patterns:
            match = re.search(pattern, normalized)
            if match:
                return match.group(1)

        # Fallback: use first 50 chars
        return normalized[:50].strip()


# Singleton instance
_manager_instance = None


def get_knowledge_manager() -> SessionKnowledgeManager:
    """Get singleton instance of knowledge manager."""
    global _manager_instance
    if _manager_instance is None:
        _manager_instance = SessionKnowledgeManager()
    return _manager_instance


if __name__ == "__main__":
    # Test the manager
    manager = SessionKnowledgeManager()

    # Simulate storing error solutions
    manager.store_error_solution(
        error_message="sqlite3.OperationalError: database is locked at line 123",
        fix_description="Changed src/web/routes/monitoring.py to use config_state.get_analysis_history()",
        files_affected=["src/web/routes/monitoring.py"],
        success=True
    )

    # Check if we know this error
    fix = manager.check_known_error("database is locked")
    if fix:
        print(f"âœ“ Known error found!")
        print(f"  Fix: {fix['fix']}")
        print(f"  Success rate: {fix['success_rate']}")
        print(f"  Used {fix['_meta']['usage_count']} times")

    # Get session insights
    insights = manager.get_session_insights()
    print(f"\nSession Insights:")
    print(json.dumps(insights, indent=2))
